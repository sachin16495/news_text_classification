{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from scipy.spatial.distance import cdist\n",
    "from tensorflow.python.keras.models import Sequential,load_model\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.layers import LSTM,Dense,GRU,Embedding,SpatialDropout1D\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below responsible for cleasning the text by replacing symbols and handling nana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clense_frame(text_df):\n",
    "    text_frm=[]\n",
    "    mid=0\n",
    "    for sm in text_df:\n",
    "        #print(sm)\n",
    "        st=str(sm)\n",
    "        if st=='nan':\n",
    "            st='unk'\n",
    "        smal=st.lower()\n",
    "        substitutions={\"'\":\"\",\"(\":\"\",\")\":\"\",\"+\":\"\"}\n",
    "        listt=[\"(\",\")\",\"'\",\"-\",\"\\n\"]\n",
    "        for ls in listt:\n",
    "            smal=smal.replace(ls,\"\")\n",
    "        #print(smal)\n",
    "        splitext=smal.split(' ')\n",
    "        #splitext=splitext.split('\\n')\n",
    "        mid=mid+len(splitext)\n",
    "        text_frm.append(splitext)\n",
    "    mid=mid/len(text_df)\n",
    "    mid=math.floor(mid)#flor(mid)\n",
    "    return text_frm,mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_clip(dafrm,maxlen):\n",
    "    padded_frame=[]\n",
    "    pword_frame=[]\n",
    "    co=0\n",
    "    \n",
    "    for df in dafrm:\n",
    "        lendf=len(df)\n",
    "        pword_frame=[]\n",
    "        if lendf<maxlen:\n",
    "            pad_len=maxlen-lendf\n",
    "            pword_frame=df\n",
    "            for pa in range(0,pad_len):\n",
    "                pword_frame.extend('p')\n",
    "        else:\n",
    "            pword_frame=df[:maxlen]\n",
    "            #print(pword_frame)\n",
    "            co=co+1\n",
    "        padded_frame.append(pword_frame)\n",
    "             \n",
    "    return padded_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexcel=pd.read_excel(\"news_details.xlsx\")\n",
    "dfexcel_cat=pd.read_excel(\"category_mapping.xlsx\")\n",
    "text_df=pd.merge(dfexcel,dfexcel_cat,on='news_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amout=round(len(text_df)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlen=len(text_df)-amout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlen=round(amout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test split of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test =text_df[:trainlen],text_df[trainlen:]# model_selection.train_test_split(X,Y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4847"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=text_df['snippet']\n",
    "Y=text_df['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=text_df['snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5386"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=X_train['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,mid=text_clense_frame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words=mid\n",
    "#Tokenize the text\n",
    "tokenize=Tokenizer(num_words=num_words)\n",
    "tokenize.fit_on_texts(X)\n",
    "idx=tokenize.word_index\n",
    "x_train_token=tokenize.texts_to_sequences(X)\n",
    "#x_test_token=tokenize.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Tokens\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "num_tokens=[len(token) for token in x_train_token]\n",
    "num_tokens=np.array(num_tokens)\n",
    "max_tokens=np.mean(num_tokens)+2*np.std(num_tokens)\n",
    "max_tokens=int(max_tokens)\n",
    "print(\"Max Tokens\")\n",
    "print(max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=list(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=[t-1 for t in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical conversion of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "catres_label=np_utils.to_categorical(lis, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad the sequnce with low length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad='pre'\n",
    "x_train_pad=pad_sequences(x_train_token,maxlen=max_tokens,padding=pad,truncating=pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5386"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture with lstm and and embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 64)            12800     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 46,279\n",
      "Trainable params: 46,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reuse_word = 200\n",
    "#Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(reuse_word, 64, input_length=max_tokens))\n",
    "model.add(LSTM(64, dropout=0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment below to start training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train_pad, catres_label, epochs=100, batch_size=100,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pridct_label(testperoc):\n",
    "    pr_label=[]\n",
    "    for i in testperoc:\n",
    "        ind = np.unravel_index(np.argmax(i, axis=None), i.shape)\n",
    "        \n",
    "        pr_label.append(ind[0])\n",
    "    pr_label=[(prt+1) for prt in pr_label]\n",
    "    return pr_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"H5 weightLSTM/modeltsnippt.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sniptrainlabel=pridct_label(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"H5 weightLSTM/descrips_text.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model.predict(x_train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "descptrainlabel=pridct_label(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"H5 weightLSTM/modeltitle.h5\")\n",
    "pred2 = model.predict(x_train_pad)\n",
    "titlelabel=pridct_label(pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the bagging with Pearson correlation coefficient and apply weighted average on the test prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4847"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlecoff=np.nan_to_num(pearsonr(titlelabel, Y_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6741\n"
     ]
    }
   ],
   "source": [
    "titlecoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "snipcoff=np.nan_to_num(pearsonr(sniptrainlabel, Y_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2146\n"
     ]
    }
   ],
   "source": [
    "snipcoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "desccoff=np.nan_to_num(pearsonr(descptrainlabel,Y_train)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1113\n"
     ]
    }
   ],
   "source": [
    "desccoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "snipptest=X_test['snippet']\n",
    "titletest=X_test['title']\n",
    "descrip_test=X_test['news_description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"H5 weightLSTM/modeltsnippt.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words1=100\n",
    "#Tokenize the text\n",
    "tokenize1=Tokenizer(num_words=num_words1)\n",
    "tokenize1.fit_on_texts(X_train)\n",
    "idx=tokenize.word_index\n",
    "x_test_tokensnip=tokenize.texts_to_sequences(snipptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad='pre'\n",
    "x_test_padsnip=pad_sequences(x_test_tokensnip,maxlen=10,padding=pad,truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtest1 = model.predict(x_test_padsnip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sniptestplabels=pridct_label(predtest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"H5 weightLSTM/modeltitle.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words2=100\n",
    "tokenize2=Tokenizer(num_words=num_words2)\n",
    "tokenize2.fit_on_texts(titletest)\n",
    "idx=tokenize.word_index\n",
    "x_test_tokentitle=tokenize.texts_to_sequences(titletest)\n",
    "pad='pre'\n",
    "x_test_title_token=pad_sequences(x_test_tokentitle,maxlen=10,padding=pad,truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_modeltitle=pad_sequences(x_test_title_token,maxlen=10,padding=pad,truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtest2=model.predict(x_test_modeltitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "titletestplabels=pridct_label(predtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"H5 weightLSTM/descrips_text.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words3=100\n",
    "Tokenize the text\n",
    "tokenize3=Tokenizer(num_words=num_words3)\n",
    "tokenize3.fit_on_texts(descrip_test)\n",
    "idx=tokenize.word_index\n",
    "x_test_tokentitle=tokenize.texts_to_sequences(descrip_test)\n",
    "pad='pre'\n",
    "x_test_descrip_token=pad_sequences(x_test_tokentitle,maxlen=10,padding=pad,truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtest3 = model.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "desctesplabels=pridct_label(predtest3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scarmul(lis1,elem,lis2,elem1,lis3,elem3):\n",
    "    listfi=[]\n",
    "    for a,b,c in zip(lis1,lis2,lis3):\n",
    "        cal=round((a*elem)+(b*elem1)+(c*elem3))\n",
    "        listfi.append(cal)\n",
    "    return listfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rest=scarmul(sniptestplabels,snipcoff,titletestplabels,titlecoff,desctesplabels,desccoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.26754\n"
     ]
    }
   ],
   "source": [
    "f1_score(Y_test, predicted_rest,average='macro')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit(Y_test)\n",
    "y_test = lb.transform(Y_test)\n",
    "y_pred = lb.transform(predicted_rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5879\n"
     ]
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
